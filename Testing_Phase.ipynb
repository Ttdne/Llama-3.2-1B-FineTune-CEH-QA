{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8d4c6945f7a481aaa50ea6f3dcd9fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_bcd476410344440cb2e6e23b8e34cda1"
          }
        },
        "2e04a1f54f9b41b0b1ebed3e0b794333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_622785d692754010a23d174cd024d2bd",
            "placeholder": "​",
            "style": "IPY_MODEL_b10e3888ddb54fe8a38dec2242f611cf",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "5efe14d3dbfd4916a0697786b1de43c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_755c77e838c146bf9a3300b1773a62b9",
            "placeholder": "​",
            "style": "IPY_MODEL_12cb6a3637b04512959fb97aad0d02f5",
            "value": ""
          }
        },
        "44abb3e9a27d4d25aae974720b36f81c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a175bc89f5364504963dc4e4da907b15",
            "style": "IPY_MODEL_a400fb3c00894329914d78b77cb2b702",
            "value": true
          }
        },
        "a222618cf9f043d9bd2b8dbcf9e70f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_0b5bf7f962dc48f0803516b1a43f64f4",
            "style": "IPY_MODEL_40c0ebbb9a7344d7af5110ba4f3faec4",
            "tooltip": ""
          }
        },
        "8361fae62b5d4002a75ddb04519cb56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c66270b9cd74f708c97b3bd032e5f75",
            "placeholder": "​",
            "style": "IPY_MODEL_02d1e5c7e75b409dacfd7077774b8655",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "bcd476410344440cb2e6e23b8e34cda1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "622785d692754010a23d174cd024d2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10e3888ddb54fe8a38dec2242f611cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "755c77e838c146bf9a3300b1773a62b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12cb6a3637b04512959fb97aad0d02f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a175bc89f5364504963dc4e4da907b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a400fb3c00894329914d78b77cb2b702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b5bf7f962dc48f0803516b1a43f64f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c0ebbb9a7344d7af5110ba4f3faec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4c66270b9cd74f708c97b3bd032e5f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d1e5c7e75b409dacfd7077774b8655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a0f8528be2400db1b4afef78015b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5b0d2232319401d82201978565e45d9",
            "placeholder": "​",
            "style": "IPY_MODEL_613a48c7ba7f4f0e9eb63985dc0663ed",
            "value": "Connecting..."
          }
        },
        "b5b0d2232319401d82201978565e45d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "613a48c7ba7f4f0e9eb63985dc0663ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Các cài đặt cấu hình cần thiết"
      ],
      "metadata": {
        "id": "0Mxs0j77N-d3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Đăng nhập vào Hugging Face, nhập token khi hệ thống yêu cầu"
      ],
      "metadata": {
        "id": "jDABZL8XLFky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  from huggingface_hub import login\n",
        "\n",
        "  # Nhập token API của bạn tại đây\n",
        "  login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "b8d4c6945f7a481aaa50ea6f3dcd9fc0",
            "2e04a1f54f9b41b0b1ebed3e0b794333",
            "5efe14d3dbfd4916a0697786b1de43c9",
            "44abb3e9a27d4d25aae974720b36f81c",
            "a222618cf9f043d9bd2b8dbcf9e70f08",
            "8361fae62b5d4002a75ddb04519cb56b",
            "bcd476410344440cb2e6e23b8e34cda1",
            "622785d692754010a23d174cd024d2bd",
            "b10e3888ddb54fe8a38dec2242f611cf",
            "755c77e838c146bf9a3300b1773a62b9",
            "12cb6a3637b04512959fb97aad0d02f5",
            "a175bc89f5364504963dc4e4da907b15",
            "a400fb3c00894329914d78b77cb2b702",
            "0b5bf7f962dc48f0803516b1a43f64f4",
            "40c0ebbb9a7344d7af5110ba4f3faec4",
            "4c66270b9cd74f708c97b3bd032e5f75",
            "02d1e5c7e75b409dacfd7077774b8655",
            "13a0f8528be2400db1b4afef78015b2a",
            "b5b0d2232319401d82201978565e45d9",
            "613a48c7ba7f4f0e9eb63985dc0663ed"
          ]
        },
        "id": "wdDBaTjJ9hgn",
        "outputId": "c910ce2f-56ef-47bf-b32d-9df31af113cf"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8d4c6945f7a481aaa50ea6f3dcd9fc0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cài đặt package hỗ trợ **Unsloth**\n",
        "\n",
        "Khi cài đặt xong bạn phải khởi động lại phiên"
      ],
      "metadata": {
        "id": "txkaKbRONAPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-1-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
        "!pip install unsloth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MAub3hzVL4PB",
        "outputId": "97ffbc44-fd71-405b-cf28-2756175abd98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping unsloth as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --no-1-dir\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2024.12.11-py3-none-any.whl.metadata (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo>=2024.12.5 (from unsloth)\n",
            "  Downloading unsloth_zoo-2024.12.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting bitsandbytes (from unsloth)\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.5-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.47.1)\n",
            "Collecting datasets>=2.16.0 (from unsloth)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\n",
            "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\n",
            "Collecting protobuf<4.0.0 (from unsloth)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.27.0)\n",
            "Collecting hf_transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2024.12.5->unsloth)\n",
            "  Downloading cut_cross_entropy-24.12.3-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.12.5->unsloth) (11.0.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n",
            "Downloading unsloth-2024.12.11-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.2/175.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.13.0-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2024.12.6-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.5-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading cut_cross_entropy-24.12.3-py3-none-any.whl (22 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, triton, shtab, protobuf, hf_transfer, fsspec, dill, multiprocess, xformers, tyro, cut_cross_entropy, bitsandbytes, datasets, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.0 cut_cross_entropy-24.12.3 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 hf_transfer-0.1.8 multiprocess-0.70.16 protobuf-3.20.3 shtab-1.7.1 triton-3.1.0 trl-0.13.0 tyro-0.9.5 unsloth-2024.12.11 unsloth_zoo-2024.12.6 xformers-0.0.28.post3 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "08d6f4cb0f6f413db8f0211e9c6aca81"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dữ liệu và xử lý trích xuất câu hỏi và câu trả lời tham chiếu dùng để đánh giá"
      ],
      "metadata": {
        "id": "Kb1GEBv9LXOO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HWuoQi4chvY8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"B1_a.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"question\", \"llm_answer\"]]\n",
        "Question = df[\"question\"]\n",
        "Evaluation = df[\"llm_answer\"]\n",
        "Question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "8E-Jfj83h1K6",
        "outputId": "41c532fa-b405-46d9-d16a-bcc199d20433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      You have successfully logged on a Linux system...\n",
              "1      What is the following command used for?\\nsqlma...\n",
              "2      Sam, a web developer, was instructed to incorp...\n",
              "3      Which of the following is assured by the use o...\n",
              "4      What is not a PCI compliance recommendation?\\n...\n",
              "                             ...                        \n",
              "145    A DDOS attack is performed at layer 7 to take ...\n",
              "146    A post-breach forensic investigation revealed ...\n",
              "147    Mirai malware targets loT devices. After infil...\n",
              "148    Thomas, a cloud security professional, is perf...\n",
              "149    Tony wants to integrate a 128-bit symmetric bl...\n",
              "Name: question, Length: 150, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You have successfully logged on a Linux system...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the following command used for?\\nsqlma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sam, a web developer, was instructed to incorp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Which of the following is assured by the use o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is not a PCI compliance recommendation?\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>A DDOS attack is performed at layer 7 to take ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>A post-breach forensic investigation revealed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>Mirai malware targets loT devices. After infil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Thomas, a cloud security professional, is perf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>Tony wants to integrate a 128-bit symmetric bl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cấu hình cho việc upload và xử lý dữ liệu với mô hình Gemini trong môi trường Google Colab."
      ],
      "metadata": {
        "id": "AMnLXXKDN8Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ],
      "metadata": {
        "id": "Am3sLTrkpR0y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary modules.\n",
        "import base64\n",
        "import copy\n",
        "import json\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "try:\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"🔑\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model1 = 'gemini-2.0-flash-exp' # @param {isTemplate: true}\n",
        "contents_b64 = 'W10=' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo0MCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "# Convert and upload the files\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data, index):\n",
        "    \"\"\"Upload files to the Files API.\n",
        "\n",
        "    For each file, Google AI Studio either sent:\n",
        "    - a Google Drive ID,\n",
        "    - a URL,\n",
        "    - a file path, or\n",
        "    - The raw bytes (`inline_data`).\n",
        "\n",
        "    The API only understands `inline_data` or it's Files API.\n",
        "    This code, uploads files to the files API where the API can access them.\n",
        "    \"\"\"\n",
        "\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        path = tempfiles / str(index)\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"📁 Files\" in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "\n",
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "index = 0\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data, index)\n",
        "            index += 1\n",
        "\n",
        "import json\n",
        "print(json.dumps(contents, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcPyyR6-pUaR",
        "outputId": "3f135832-3634-445d-fbcd-e72e37ac4292"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini = genai.GenerativeModel(model_name=model1)\n"
      ],
      "metadata": {
        "id": "bib_F1B-OrWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khởi tạo hàm đánh giá chất lượng câu trả lời được đưa ra bởi mô hình bằng Gemini"
      ],
      "metadata": {
        "id": "jsjzxSFQOhcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_explanation_gemini(question, reference_text, model_answer_text):\n",
        "    prompt = f\"\"\"\n",
        "You are an expert evaluator. Evaluate the quality of an explanation provided by a model based on its accuracy, clarity, and relevance.\n",
        "\n",
        "### Question:\n",
        "{question}\n",
        "\n",
        "### Reference Answer and Explanation:\n",
        "{reference_text}\n",
        "\n",
        "### Model Answer and Explanation:\n",
        "{model_answer_text}\n",
        "\n",
        "### Evaluation Criteria: First, if model just gives answer under format (A, B, C, D) with no reasoning explaination, give it 20 points overall if correct answer, 0 overall if incorrect and skip below criteria.\n",
        "- **Accuracy**: Does the answer correctly explain the reference answer and are given with explaination? (50 points)\n",
        "- **Clarity**: Is the explanation easy to understand and well-structured? (30 points)\n",
        "- **Relevance**: Is the explanation focused on the question and reference answer? (20 points)\n",
        "\n",
        "### Task:\n",
        "Provide a score from 0 to 100 based on the above criteria briefly with no explaination\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "    # Gửi yêu cầu đánh giá tới API của Gemini\n",
        "    response = gemini.generate_content(\n",
        "          contents=prompt,\n",
        "          generation_config=generation_config,\n",
        "          safety_settings=safety_settings,\n",
        "          stream=stream,\n",
        "    )\n",
        "    return Markdown(response.text)"
      ],
      "metadata": {
        "id": "EPjcomNsp1Fq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Đánh giá mô hình sau khi finetune\n",
        "\n",
        "Khởi tạo mô hình Llama sau finetune bằng gói **FastLanguageModel** từ **Unsloth**.\n",
        " Lưu ý rằng gói này chỉ hỗ trợ mô hình chạy trên GPU T4, vì vậy người dùng cần chọn\n",
        "đúng loại thời gian chạy là T4 GPU"
      ],
      "metadata": {
        "id": "WpO9W18GNzaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "max_seq_length = 4084 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"How can rainbow tables be defeated? \\A.  Use of non-dictionary words \\B.  All uppercase character passwords \\C.  Password salting \\D.  Lockout accounts under brute force password cracking attempts\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ")\n",
        "inputs = inputs.to('cuda')\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ],
      "metadata": {
        "id": "Z8YiNNBiNvB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_score = []"
      ],
      "metadata": {
        "id": "OmjlFRjww017"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Đoạn code dưới đây duyệt qua danh sách câu hỏi, đưa vào mô hình để tạo ra câu trả lời rồi dùng hàm **evaluate_explanation_gemini** đã được định nghĩa bên trên để đánh giá. Vì API key người thi sử dụng là bản miễn phí từ Google AI Studio có giới hạn tokens nên khuyến khích người dùng chạy code trên từng đoạn 15 dữ liệu riêng lẻ nếu không có key bản trả phí. Ví dụ:\n",
        "\n",
        "\n",
        "```\n",
        "for i in range(0, 15):\n",
        "...\n",
        "for i in range(15, 30):\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0D4CXExQOxCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range('''bắt đầu''', '''kết thúc'''):  # Duyệt qua tất cả các câu hỏi\n",
        "    input_text = Question[i]  # Câu hỏi hiện tại\n",
        "    reference_text = [Evaluation[i]]  # Câu trả lời đúng dưới dạng danh sách\n",
        "\n",
        "    # Kiểm tra và thêm pad_token nếu cần\n",
        "\n",
        "    # Mã hóa input_text\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
        "\n",
        "    # Sinh văn bản từ mô hình\n",
        "    output = model.generate(input_ids=inputs['input_ids'], max_new_tokens=128)\n",
        "    prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    evaluation = evaluate_explanation_gemini(input_text, reference_text, prediction)\n",
        "    print(f\"--- Evaluation for Question {i+1} ---\")\n",
        "    markdown_text = evaluation.data  # Lấy dữ liệu (nội dung chuỗi) từ đối tượng Markdown\n",
        "\n",
        "    # Chuyển đổi chuỗi thành integer nếu có thể\n",
        "    try:\n",
        "        integer_value = int(markdown_text)  # Cố gắng chuyển chuỗi thành số nguyên\n",
        "        print(f\"Converted integer value: {integer_value}\")\n",
        "        list_score.append(integer_value)\n",
        "    except ValueError:\n",
        "        print(\"The content is not convertible to an integer.\")\n",
        "    print(integer_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGExkXCap_xR",
        "outputId": "82210329-d3fb-4f24-cede-be3ce0c707ca"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluation for Question 144 ---\n",
            "Converted integer value: 75\n",
            "75\n",
            "--- Evaluation for Question 145 ---\n",
            "Converted integer value: 25\n",
            "25\n",
            "--- Evaluation for Question 146 ---\n",
            "Converted integer value: 60\n",
            "60\n",
            "--- Evaluation for Question 147 ---\n",
            "Converted integer value: 20\n",
            "20\n",
            "--- Evaluation for Question 148 ---\n",
            "Converted integer value: 55\n",
            "55\n",
            "--- Evaluation for Question 149 ---\n",
            "Converted integer value: 20\n",
            "20\n",
            "--- Evaluation for Question 150 ---\n",
            "Converted integer value: 0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLhn-2vT4qnr",
        "outputId": "7f3b1bf4-acda-4d62-dc1b-9bed801eceff"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Tạo DataFrame từ list_score\n",
        "df = pd.DataFrame(list_score, columns=['Score'])\n",
        "\n",
        "# Hiển thị bảng\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b_NldAKVxFLa",
        "outputId": "52e8deed-c276-403b-bace-ee4c9562072b"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Score\n",
              "0       25\n",
              "1       20\n",
              "2       90\n",
              "3       80\n",
              "4       15\n",
              "..     ...\n",
              "146     60\n",
              "147     20\n",
              "148     55\n",
              "149     20\n",
              "150      0\n",
              "\n",
              "[151 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74ee1349-32fa-4790-a42d-9f7446730b59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74ee1349-32fa-4790-a42d-9f7446730b59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74ee1349-32fa-4790-a42d-9f7446730b59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74ee1349-32fa-4790-a42d-9f7446730b59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-082bd2ba-d916-467e-b10e-6c2ba96e108f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-082bd2ba-d916-467e-b10e-6c2ba96e108f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-082bd2ba-d916-467e-b10e-6c2ba96e108f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f34a55f6-5bd2-4c87-95ff-c27a9a8af0fe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f34a55f6-5bd2-4c87-95ff-c27a9a8af0fe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 151,\n  \"fields\": [\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 0,\n        \"max\": 100,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          25,\n          75,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biểu đồ tần suất mức điểm xuất hiện trên toàn bộ tập đánh giá sau khi finetune mô hình"
      ],
      "metadata": {
        "id": "PNfH2eRjQLKS"
      }
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "df['Score'].plot(kind='hist', bins=20, title='Score')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n"
      ],
      "cell_type": "code",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "AeMO7QU782E8",
        "outputId": "c934028c-f2e7-454a-becc-1d45bf6f472d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Điểm trung bình trên toàn tập dữ liệu"
      ],
      "metadata": {
        "id": "EmzglYAGQdQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "print(\"Average point\",statistics.mean(list_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVKKRjETxXvD",
        "outputId": "da3ad19d-85d0-4ee2-86a5-7fa486916a4e"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average point 36.88741721854305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Đánh giá mô hình trước khi finetune\n"
      ],
      "metadata": {
        "id": "p7VWC-drQk75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "# Import Llama 3.2 1B from Hugging Face\n",
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "max_seq_length = 4096\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "model.config.max_seq_length = max_seq_length\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "Uq511r_x9_Er",
        "outputId": "b10dff98-3864-4bdc-f716-436e7b3a2e60"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 13.06 MiB is free. Process 5327 has 14.73 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 21.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-1176f90ebc89>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'pad_token'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'[PAD]'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4129\u001b[0m             \u001b[0;31m# Let's make sure we don't run the init function of buffer modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4130\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4132\u001b[0m         \u001b[0;31m# make sure we use the model's config since the __init__ call might have copied it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    810\u001b[0m         )\n\u001b[1;32m    811\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaRMSNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms_norm_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaRotaryEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim, max_position_embeddings, base, device, config)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m# Build here to make `torch.jit.trace` work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_cos_sin_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_rope_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_set_cos_sin_cache\u001b[0;34m(self, seq_len, device, dtype)\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cos_cached\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sin_cached\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 13.06 MiB is free. Process 5327 has 14.73 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 21.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_score_origin = []"
      ],
      "metadata": {
        "id": "3KRwC17uQ6Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(145,150):  # Sử dụng 1 câu hỏi để kiểm tra\n",
        "    # Sử dụng mô hình như bình thường\n",
        "    input_text = Question[i]\n",
        "    if model.config.pad_token_id is None: # Set pad_token_id if not set\n",
        "        model.config.pad_token_id = model.config.eos_token_id\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    if 'attention_mask' not in inputs:\n",
        "        inputs['attention_mask'] = torch.ones_like(inputs['input_ids'])\n",
        "    # Sinh văn bản\n",
        "    output = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=128)\n",
        "\n",
        "    # In kết quả\n",
        "    prediction_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Ensure Evaluation[i] is a list of strings\n",
        "    reference_text = Evaluation[i]  # Assume it's a string, not a list for this case\n",
        "\n",
        "    # Giả sử evaluate_explanation_gemini là một hàm để đánh giá giải thích từ mô hình\n",
        "    evaluation = evaluate_explanation_gemini(input_text, reference_text, prediction_text)\n",
        "    print(f\"--- Evaluation for Question {i+1} ---\")\n",
        "    markdown_text = evaluation.data  # Lấy dữ liệu (nội dung chuỗi) từ đối tượng Markdown\n",
        "\n",
        "    # Chuyển đổi chuỗi thành integer nếu có thể\n",
        "    try:\n",
        "        integer_value = int(markdown_text)  # Cố gắng chuyển chuỗi thành số nguyên\n",
        "        print(f\"Converted integer value: {integer_value}\")\n",
        "        list_score_origin.append(integer_value)\n",
        "    except ValueError:\n",
        "        print(\"The content is not convertible to an integer.\")"
      ],
      "metadata": {
        "id": "OrxsjzubQ7Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_score_origin)"
      ],
      "metadata": {
        "id": "tAtDKq5WRAbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Tạo DataFrame từ list_score\n",
        "df = pd.DataFrame(list_score_origin, columns=['Score'])\n",
        "\n",
        "# Hiển thị bảng\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "MzBQ1jZYpMZL",
        "outputId": "7e15d547-e179-4ad4-84ca-21c758c81d27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'list_score_origin' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-80005f707249>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Tạo DataFrame từ list_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_score_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Hiển thị bảng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'list_score_origin' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Score\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "df['Score'].plot(kind='hist', bins=20, title='Score')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "metadata": {
        "id": "ADm_pMfhRF6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "print(\"Average point\",statistics.mean(list_score_origin))"
      ],
      "metadata": {
        "id": "Akr9iWL1RGnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lkuNyv9aRIbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}